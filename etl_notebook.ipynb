{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DB_NAME</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DB_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Param     Value\n",
       "0      DB_NAME       dwh\n",
       "1      DB_USER   dwhuser\n",
       "2  DB_PASSWORD  Passw0rd\n",
       "3      DB_PORT      5439"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFIG\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "DB_NAME                 = config.get(\"CLUSTER\",\"DB_NAME\")\n",
    "DB_USER                 = config.get(\"CLUSTER\",\"DB_USER\")\n",
    "DB_PASSWORD             = config.get(\"CLUSTER\",\"DB_PASSWORD\")\n",
    "DB_PORT                 = config.get(\"CLUSTER\",\"DB_PORT\")\n",
    "HOST                    =config.get(\"CLUSTER\", \"HOST\")\n",
    "\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DB_NAME\", \"DB_USER\", \"DB_PASSWORD\", \"DB_PORT\"],\n",
    "              \"Value\":\n",
    "                  [DB_NAME, DB_USER, DB_PASSWORD, DB_PORT]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating IAM User, EC2, S3 and Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.resource('ec2',\n",
    "                       region_name=\"us-west-2\"\n",
    "                    )\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=\"us-west-2\"\n",
    "                   )\n",
    "\n",
    "iam = boto3.client('iam', \n",
    "                     region_name='us-west-2'\n",
    "                  )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name=\"us-west-2\"\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting a sample song data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 path\n",
    "# s3://udacity-dend/log_json_path.json\n",
    "\n",
    "file = s3.Object(\"udacity-dend\", 'log_json_path.json')\n",
    "content = json.loads(file.get()['Body'].read())\n",
    "print(json.dumps(content, indent=4, sort_keys=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting s3 objects using S3 Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_col = s3.Bucket(\"udacity-dend\").objects.filter(Prefix = 'song_data/')\n",
    "\n",
    "# print(list(obj_col)[0])\n",
    "for i, obj in enumerate(obj_col):\n",
    "    print(obj.key)\n",
    "    if i > 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of getting list of objects paths in S3 using Client (just another way of doing it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3',\n",
    "                       region_name=\"us-west-2\"\n",
    "                   )\n",
    "\n",
    "lst_contents = s3_client.list_objects(Bucket=\"udacity-dend\", Prefix='song_data')['Contents']\n",
    "\n",
    "print(\"list length: {}\".format(len(lst_contents)))\n",
    "\n",
    "print(lst_contents[0])\n",
    "print(lst_contents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting the content from 1 file in S3 bucket as a sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting song_data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = s3.Bucket(\"udacity-dend\").objects.filter(Prefix = 'song_data')\n",
    "\n",
    "# getting a sample data from the original dataset\n",
    "file = s3.Object(\"udacity-dend\", 'song_data/A/A/A/TRAAAAV128F421A322.json')\n",
    "\n",
    "# printing in a pretty JSON format\n",
    "content = json.loads(file.get()['Body'].read())\n",
    "print(json.dumps(content, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting song_data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_col = s3.Bucket(\"udacity-dend\").objects.filter(Prefix = 'log_data/')\n",
    "\n",
    "# print(list(obj_col)[0])\n",
    "for i, obj in enumerate(obj_col):\n",
    "    print(obj.key)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj_log = s3.Object(\"udacity-dend\", 'log_data/2018/11/2018-11-03-events.json')\n",
    "obj_log = s3.Object(\"udacity-dend\", 'log_data/2018/11/2018-11-06-events.json')\n",
    "\t# s3://udacity-dend/log_data/2018/11/2018-11-06-events.json\n",
    "\n",
    "\n",
    "content_log = obj_log.get()['Body'].read().decode(\"utf-8\")\n",
    "\n",
    "df_log = pd.read_json(path_or_buf=content_log, orient='records', lines=True)\n",
    "df_log.head(10)\n",
    "# df_log[df_log.page == 'NextSong'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "print(\"Original Extraction\")\n",
    "print(\"Obj type (Bytes): {0}\".format(type(obj_log.get()['Body'].read())))\n",
    "print(\"Obj type (Converted to string): {0}\".format(type(obj_log.get()['Body'].read().decode(\"utf-8\"))))\n",
    "\n",
    "# print(\"Sample\")\n",
    "print(\"Sample string \\n {0}\".format(obj_log.get()['Body'].read().decode(\"utf-8\")[:1000])) # print the first 1000 characters\n",
    "\n",
    "print()\n",
    "print(\"Converted Pandas Dataframe\")\n",
    "df_log.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DB_USER, DB_PASSWORD, HOST, DB_PORT, DB_NAME)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from tb_dim_users;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSERT INTO tb_fact_songplays \n",
      "(start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)\n",
      "SELECT\n",
      "    a.ts            as start_time,      \n",
      "    a.userId        as user_id,         \n",
      "    a.level         as level,           \n",
      "    b.song_id       as song_id,         \n",
      "    b.artist_id     as artist_id,       \n",
      "    a.sessionId     as session_id,      \n",
      "    a.location      as location,        \n",
      "    a.userAgent     as user_agent     \n",
      "FROM tb_staging_events as a\n",
      "JOIN tb_staging_songs as b\n",
      "    on upper(trim(a.artist)) = upper(trim(b.artist_name))\n",
      "    and upper(trim(a.song)) = upper(trim(b.title))\n",
      "WHERE trim(a.page) = 'NextSong'\n",
      ";\n",
      "\n",
      "\n",
      "INSERT INTO tb_dim_users\n",
      "(user_id, first_name, last_name, gender, level)\n",
      "SELECT\n",
      "    userId as user_id,     \n",
      "    firstName as first_name,\n",
      "    lastName as last_name,\n",
      "    gender as gender,\n",
      "    level as level\n",
      "FROM tb_staging_events\n",
      "WHERE trim(page) = 'NextSong'\n",
      ";\n",
      "\n",
      "\n",
      "INSERT INTO tb_dim_songs\n",
      "(song_id, title, artist_id, year, duration)\n",
      "SELECT\n",
      "    song_id as song_id,  \n",
      "    title as title,    \n",
      "    artist_id as artist_id,\n",
      "    year as year,     \n",
      "    duration as duration \n",
      "FROM tb_staging_songs;\n",
      "\n",
      "\n",
      "INSERT INTO tb_dim_artists\n",
      "(artist_id, name, location, latitude, longitude)\n",
      "SELECT\n",
      "    artist_id as artist_id,\n",
      "    artist_name as name,     \n",
      "    artist_location as location, \n",
      "    artist_latitude as latitude, \n",
      "    artist_longitude as longitude\n",
      "FROM tb_staging_songs;\n",
      "\n",
      "\n",
      "INSERT INTO tb_dim_time\n",
      "(start_time, hour, day, week, month, year, weekday)\n",
      "SELECT\n",
      "    ts as start_time,\n",
      "    EXTRACT(hour FROM ts) as hour,      \n",
      "    EXTRACT(day FROM ts) as day,       \n",
      "    EXTRACT(week FROM ts) as week,      \n",
      "    EXTRACT(month FROM ts) as month,     \n",
      "    EXTRACT(year FROM ts) as year,      \n",
      "    EXTRACT(weekday FROM ts) as weekday   \n",
      "FROM tb_staging_events;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sql_queries import copy_table_queries, insert_table_queries\n",
    "\n",
    "def load_staging_tables(cur, conn):\n",
    "    for query in copy_table_queries:\n",
    "        print(query)[:50]\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def insert_tables(cur, conn):\n",
    "    for query in insert_table_queries:\n",
    "        print(query)[:50]\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "cur = conn.cursor()\n",
    "\n",
    "load_staging_tables(cur, conn)\n",
    "insert_tables(cur, conn)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select \n",
    "count(1)\n",
    "from tb_staging_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select \n",
    "count(1)\n",
    "from tb_staging_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT\n",
    "    count(1) as qtd\n",
    "FROM tb_staging_events as a\n",
    "LEFT JOIN tb_staging_songs as b\n",
    "    on upper(trim(a.artist)) = upper(trim(b.artist_name))\n",
    "    and upper(trim(a.song)) = upper(trim(b.title))\n",
    "WHERE trim(a.page) = 'NextSong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('dw_proj_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb14a3c8574eaa758f3be984b33f9b755e81026837ee03e8f050b49bfbceb090"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
